{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train a convolutional model to predict log fold change f K27act from sequence and atac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/kal/TF_models/bin/sequence.py:275: RuntimeWarning: divide by zero encountered in log\n",
      "  self.seq = helper.softmax(np.log(dist))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/kal/TF_models/bin/')\n",
    "sys.path.append('/home/kal/K27act_models/convolution_model/')\n",
    "sys.path.append('/home/kal/K27act_models/cg_model/')\n",
    "sys.path.append('/home/thouis/basenji_embeddings')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tf_memory_limit\n",
    "from zinb import ZINB\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sequence\n",
    "import helper\n",
    "import viz_sequence\n",
    "import ucscgenome\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datagen\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, SpatialDropout1D, Conv1D, Lambda\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load in the DNA\n",
    "genome = ucscgenome.Genome('/home/kal/.ucscgenome/hg19.2bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in ATAC data\n",
    "atac_path = '/home/kal/K27act_models/GM_data/ATAC/atac_average.hdf5'\n",
    "atac = h5py.File(atac_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in peaks data\n",
    "peaks_path = '/home/kal/K27act_models/GM_data/merged_annotated.bed'\n",
    "peaks = pd.read_table(peaks_path)\n",
    "peaks.columns='chr narrowstart narrowend name score atac k27act'.split()\n",
    "\n",
    "peaks['start'] = (peaks['narrowend'] + peaks['narrowstart'])//2 - 512\n",
    "peaks['end'] = (peaks['narrowend'] + peaks['narrowstart'])//2 + 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167190/167190 [00:41<00:00, 4061.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# preproces the data\n",
    "for idx, row in tqdm(peaks.iterrows(), total=len(peaks)):\n",
    "    peaks.set_value(idx, 'nucs', genome[row.chr][row.start:row.end])\n",
    "    #mini.set_value(idx, 'coverage', atac[row.chr][row.start:row.end])\n",
    "    \n",
    "columns='chr start end name score atac k27act nucs'.split()\n",
    "peaks.to_csv('/home/kal/K27act_models/GM_data/k27act_training_regions.bed', columns=columns, header=None, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in preprocessed data\n",
    "peaks_path = '/home/kal/K27act_models/GM_data/k27act_training_regions.bed'\n",
    "peaks = pd.read_table(peaks_path, header=None)\n",
    "peaks.columns='chr start end name score atac k27act nucs'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160363 training samples\n",
      "3413 testing samples\n",
      "3414 validation samples\n"
     ]
    }
   ],
   "source": [
    "# facts about the data\n",
    "num_training_samples = len(peaks[(peaks.chr != 'chr8')])\n",
    "print('{} training samples'.format(num_training_samples))\n",
    "\n",
    "num_testing_samples = len(peaks[(peaks.chr == 'chr8') & (peaks.index%2 == 0)])\n",
    "print('{} testing samples'.format(num_testing_samples))\n",
    "\n",
    "num_validaiton_samples = len(peaks[(peaks.chr == 'chr8') & (peaks.index%2 == 1)])\n",
    "print('{} validation samples'.format(num_validaiton_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory stuff\n",
    "out_dir = '/home/kal/K27act_models/convolution_model/'\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(out_dir, timestr + '_fold_pwm')\n",
    "os.makedirs(out_path)\n",
    "# make a file system\n",
    "weights_path = os.path.join(out_path, 'intermediate_weights')\n",
    "os.makedirs(weights_path)\n",
    "history_path = os.path.join(out_path, 'history')\n",
    "os.makedirs(history_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "batch_size=32\n",
    "seqs = Input(batch_shape=(batch_size, 1024, 5))\n",
    "\n",
    "def add_RC(x):\n",
    "    RC = K.concatenate([x[:, ::-1, :1], x[:, ::-1, 1:][::-1]], axis=2)\n",
    "    return K.concatenate([x, RC], axis=0)\n",
    "def add_RC_shape(s):\n",
    "    return 2*s[0], s[1], s[2]\n",
    "\n",
    "rc = Lambda(add_RC, name='add_rc', output_shape=add_RC_shape)(seqs)\n",
    "conv = Conv1D(32, 32, name='conv_in')(rc)\n",
    "dense = Dense(1)(conv)\n",
    "\n",
    "def max_by_direction(x):\n",
    "    forward_max = K.max(x[:x.shape[0]//2, :, :], axis=1)\n",
    "    reverse_max = K.max(x[x.shape[0]//2:, ::-1, :], axis=1)\n",
    "    return K.maximum(forward_max, reverse_max)\n",
    "def max_by_direction_shape(s):\n",
    "    return s[0]//2, 1\n",
    "\n",
    "wide_scan = Conv1D(1, 128, use_bias=False, kernel_initializer='ones', trainable=False, name='wide_scan', padding='valid')\n",
    "predictions = Lambda(max_by_direction, name='max_by_direciton', output_shape=max_by_direction_shape)(wide_scan(dense))\n",
    "model = Model(inputs=seqs, outputs=predictions)\n",
    "\n",
    "#plot model\n",
    "plot_model(model, to_file=os.path.join(out_path, 'model.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "\n",
    "opt = RMSprop(lr=1e-5)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error') \n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=100)\n",
    "filepath = os.path.join(weights_path, 'weights-{epoch:02d}-{val_loss:.3f}.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "losses = model.fit_generator(datagen.batch_gen(peaks, mode='train'), steps_per_epoch=num_training_samples//batch_size, \n",
    "                             epochs=20, callbacks=[early_stop, checkpoint], validation_data=datagen.batch_gen(peaks,mode='val'), \n",
    "                             validation_steps=num_validaiton_samples//batch_size, verbose=2)\n",
    "\n",
    "\n",
    "val_hist = losses.history['val_loss']\n",
    "train_hist = losses.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final save\n",
    "model.save(os.path.join(out_path, 'final_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at loss\n",
    "plt.plot(val_hist, label='validation')\n",
    "plt.plot(train_hist, label='training')\n",
    "plt.title('Loss for training model')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim((0, 10))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look at kernels\n",
    "\n",
    "# make a highlight map\n",
    "from colour import Color\n",
    "\n",
    "#what layers do we have to work with?\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers]) \n",
    "print(layer_dict.keys())\n",
    "\n",
    "# plot weights from first layer neurons\n",
    "#temp = .005\n",
    "weight_array = layer_dict['conv_in'].get_weights()[0]\n",
    "#create highlight dict - with sane maxs and mins\n",
    "colors = list(Color(\"blue\").range_to(Color(\"white\"), 50))\n",
    "[colors.append(c) for c in (Color(\"white\").range_to(Color(\"red\"), 51))]\n",
    "top = np.amax(weight_array[:, 0, :])\n",
    "bottom = np.amin(weight_array[:, 0, :])\n",
    "    \n",
    "# got throught the kernels\n",
    "for idx in range(weight_array.shape[2]):\n",
    "    weight = weight_array[:,:,idx]\n",
    "    #get hightlights!\n",
    "    color_weights = [int((x-bottom)/(top-bottom)*100) for x in weight[:,0]]\n",
    "    highlight=dict()\n",
    "    for i in range(len(weight)):\n",
    "        w = color_weights[i]\n",
    "        highlight[(colors[w].rgb[0],colors[w].rgb[1], colors[w].rgb[2], .3)] = [(i, i+1)]\n",
    "    #plot things out\n",
    "    kernel = sequence.Sequence(weight[:, 1:])\n",
    "    plt.figure(figsize=(20,2))\n",
    "    plt.title('ATAC weights and sequence for kernel {}'.format(idx))\n",
    "    plt.plot(weight[:,0])\n",
    "    plt.show()\n",
    "    viz_sequence.plot_weights(kernel.seq, highlight=highlight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
