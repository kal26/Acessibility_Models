{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train a convolutional model to predict log fold change f K27act from sequence and atac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/kal/TF_models/bin/sequence.py:275: RuntimeWarning: divide by zero encountered in log\n",
      "  self.seq = helper.softmax(np.log(dist))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/kal/TF_models/bin/')\n",
    "sys.path.append('/home/kal/K27act_models/convolution_model/')\n",
    "sys.path.append('/home/kal/K27act_models/cg_model/')\n",
    "sys.path.append('/home/thouis/basenji_embeddings')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tf_memory_limit\n",
    "from zinb import ZINB\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sequence\n",
    "import ucscgenome\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datagen\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, SpatialDropout1D, Conv1D, Lambda\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load in the DNA\n",
    "genome = ucscgenome.Genome('/home/kal/.ucscgenome/hg19.2bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in ATAC data\n",
    "atac_path = '/home/kal/K27act_models/GM_data/ATAC/atac_average.hdf5'\n",
    "atac = h5py.File(atac_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load in peaks data\n",
    "peaks_path = '/home/kal/K27act_models/GM_data/merged_annotated.bed'\n",
    "peaks = pd.read_table(peaks_path, header=None)\n",
    "peaks.columns='chr narrowstart narrowend name score atac k27act'.split()\n",
    "\n",
    "peaks['start'] = (peaks['narrowend'] + peaks['narrowstart'])//2 - 512\n",
    "peaks['end'] = (peaks['narrowend'] + peaks['narrowstart'])//2 + 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preproces the data\n",
    "for idx, row in tqdm(peaks.iterrows(), total=len(peaks)):\n",
    "    peaks.set_value(idx, 'nucs', genome[row.chr][row.start:row.end])\n",
    "    #mini.set_value(idx, 'coverage', atac[row.chr][row.start:row.end])\n",
    "    \n",
    "columns='chr start end name score atac k27act nucs'.split()\n",
    "peaks.to_csv('/home/kal/K27act_models/GM_data/k27act_training_regions.bed', columns=columns, header=None, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in preprocessed data\n",
    "peaks_path = '/home/kal/K27act_models/GM_data/k27act_training_regions.bed'\n",
    "peaks = pd.read_table(peaks_path, header=None)\n",
    "peaks.columns='chr start end name score atac k27act nucs'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140163 training samples\n",
      "3011 testing samples\n",
      "3011 validation samples\n"
     ]
    }
   ],
   "source": [
    "# facts about the data\n",
    "num_training_samples = len(peaks[(peaks.chr != 'chr8')])\n",
    "print('{} training samples'.format(num_training_samples))\n",
    "\n",
    "num_testing_samples = len(peaks[(peaks.chr == 'chr8') & (peaks.index%2 == 0)])\n",
    "print('{} testing samples'.format(num_testing_samples))\n",
    "\n",
    "num_validaiton_samples = len(peaks[(peaks.chr == 'chr8') & (peaks.index%2 == 1)])\n",
    "print('{} validation samples'.format(num_validaiton_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# directory stuff\n",
    "out_dir = '/home/kal/K27act_models/convolution_model/'\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(out_dir, timestr)\n",
    "os.makedirs(out_path)\n",
    "# make a file system\n",
    "weights_path = os.path.join(out_path, 'intermediate_weights')\n",
    "os.makedirs(weights_path)\n",
    "history_path = os.path.join(out_path, 'history')\n",
    "os.makedirs(history_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL\n",
    "batch_size=32\n",
    "seqs = Input(batch_shape=(batch_size, 1024, 5))\n",
    "\n",
    "def add_RC(x):\n",
    "    RC = K.concatenate([x[:, ::-1, :1], x[:, ::-1, 1:][::-1]], axis=2)\n",
    "    return K.concatenate([x, RC], axis=0)\n",
    "def add_RC_shape(s):\n",
    "    return 2*s[0], s[1], s[2]\n",
    "\n",
    "rc = Lambda(add_RC, name='add_rc', output_shape=add_RC_shape)(seqs)\n",
    "conv = Conv1D(32, 32, name='conv_in')(rc)\n",
    "#for k, n in [[32, 3], [32, 32], [16, 3], [8, 3]]:\n",
    "#    conv = Conv1D(k, n)(conv)\n",
    "#    conv = SpatialDropout1D(.05)(conv)\n",
    "  \n",
    "#conv = Dense(8)(conv)\n",
    "#out = Dense(1)(conv)\n",
    "\n",
    "def max_by_direction(x):\n",
    "    forward_max = K.max(x[:x.shape[0]//2, :, :], axis=1)\n",
    "    reverse_max = K.max(x[x.shape[0]//2:, ::-1, :], axis=1)\n",
    "    return K.maximum(forward_max, reverse_max)\n",
    "def max_by_direction_shape(s):\n",
    "    return s[0]//2, 1\n",
    "\n",
    "predictions = Lambda(max_by_direction, name='max_by_direciton', output_shape=max_by_direction_shape)(conv)\n",
    "model = Model(inputs=seqs, outputs=predictions)\n",
    "\n",
    "#zinb loss stuff (only for counts, not log fold change)\n",
    "#pi_layer = Dense(num_outputs, activation='sigmoid')\n",
    "#pi = pi_layer(expand)\n",
    "#zinb = ZINB(pi, theta_init=tf.zeros([1, num_outputs]))\n",
    "\n",
    "#model.layers[-1].trainable_weights.extend([zinb.theta_variable, *pi_layer.trainable_weights])\n",
    "\n",
    "#plot model\n",
    "plot_model(model, to_file=os.path.join(out_path, 'model.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 258s - loss: 3044.5503 - val_loss: 532.0186\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 532.01857, saving model to /home/kal/K27act_models/convolution_model/20180628_121908/intermediate_weights/weights-01-532.019.hdf5\n",
      "Epoch 2/20\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop, SGD, Adam\n",
    "\n",
    "opt = RMSprop(lr=1e-5)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error') \n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=100)\n",
    "filepath = os.path.join(weights_path, 'weights-{epoch:02d}-{val_loss:.3f}.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "losses = model.fit_generator(datagen.batch_gen(peaks, mode='train'), steps_per_epoch=num_training_samples//batch_size, \n",
    "                             epochs=20, callbacks=[early_stop, checkpoint], validation_data=datagen.batch_gen(peaks,mode='val'), \n",
    "                             validation_steps=num_validaiton_samples//batch_size, verbose=2)\n",
    "\n",
    "\n",
    "val_hist = losses.history['val_loss']\n",
    "train_hist = losses.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final save\n",
    "model_json = model.to_json()\n",
    "with open(os.path.join(out_path, 'model.json'), 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(os.path.oin(out_path, 'final_model.h5'))\n",
    "print('Saved model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
